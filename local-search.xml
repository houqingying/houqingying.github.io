<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【超分辨率】SRCNN-利用深度卷积网络实现图像超分辨率</title>
    <link href="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/"/>
    <url>/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/</url>
    
    <content type="html"><![CDATA[<h2 id="摘要">0 摘要</h2><p>SRCNN是低分辨率到高分辨率的端到端映射的CNN：</p><ul><li>轻量级结构</li><li>超过传统方法、最好的恢复质量</li><li>快速在线使用的速度</li><li>可以处理3个颜色通道</li></ul><figure><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/模型结果.jpeg" alt="模型结果"><figcaption aria-hidden="true">模型结果</figcaption></figure><h2 id="引言">1 引言</h2><p>单图像超分辨率(SISR)是一个ill-posed(不适定)的问题，解不是唯一的,这类问题通常通过比较强的先验信息约束解空间来缓解。</p><p>最近最先进的方法大多采用基于示例(example-based)的策略，可以设计通用的或特定领域的超分辨率方法：</p><ul><li>利用相同图像的内部相似性</li><li>学习低分辨率和高分辨率的映射函数</li></ul><p>考虑使用卷积神经网络直接学习LR和SR之间的端到端映射，提出SRCNN：</p><ul><li><strong>结构简单</strong>，但与最先进的基于实例的方法相比，提供了更高的准确性。</li><li>快，通过适当的filter和layers，实现了<strong>快速的在线实际使用</strong>。</li><li>使用更大、更多样的数据集 &amp;使用更大、更深入的模型时，网络的恢复质量可以进一步提高</li></ul><h2 id="理论">2 理论</h2><p>插值方法：</p><ul><li>最近邻插值</li><li>双线性插值（周围4个点决定该点像素值）</li><li>双三次插值（周围十六个像素值决定该点像素值）</li></ul><p>唯一要做的<strong>预处理</strong>：把低分辨率图像使用双三次插值升级到需要的尺寸，得到图片Y，目标为恢复出高分辨率的F(Y)，设真实高分辨率图像为X。</p><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/SRCNN网络结构.jpeg" style="zoom: 50%;"></p><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/SRCNN网络说明.jpeg" style="zoom: 50%;"></p><p>学习F，从<span class="label label-primary">稀疏编码</span>思想得来网络结构，F做了3件事：</p><ul><li><p><strong>Patch提取与表示</strong>：从Y中提取patch，把每个patch表示为一个高维向量。这些向量包括一组特征图，其数量等于向量的维数。<span class="math display">\[F_1(Y)=max(W_1*Y + B_1)\]</span> <span class="math inline">\(W_1\)</span>为滤波器，<span class="math inline">\(*\)</span>为卷积运算，<span class="math inline">\(B_1\)</span>为偏差，<span class="math inline">\(n_1\)</span>个<span class="math inline">\(kernel\)</span>大小为<span class="math inline">\(f_1\)</span>的filter，输出由<span class="math inline">\(n_1\)</span>个特征映射而成。</p></li><li><p><strong>非线性映射</strong>：将一个高维向量映射到另一个高维向量，将<span class="math inline">\(n_1\)</span>维的向量通过逐点卷积映射为<span class="math inline">\(n_2\)</span>维向量</p></li><li><p><strong>重建</strong>：聚合上述高分辨率的patch级表示</p></li></ul><p><span class="math display">\[F(Y)=W_3*F_2(Y) + B_3\]</span></p><p>代码中的参数：<span class="math inline">\(f_1 = 9, f_2 = 1, f_3 = 5,n_1 = 64,n_2 = 32\)</span></p><h2 id="代码实现">3 代码实现</h2><p>参考代码传送门，代码风格很好：https://github.com/yjn870/SRCNN-pytorch</p><p>由上可知，网络结构为：</p><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/image-20221002174112963.png" style="zoom: 40%;"></p><p>因为看到了另一位兄弟写的blog，假设了输入图片的size是<span class="math inline">\(33 \times33\)</span>，实际上大小没有什么影响，SRCNN并不会改变输入图片的大小，每一层的大小都保持了相同的形状。</p><p>以及mark一个<a href="http://alexlenail.me/NN-SVG/AlexNet.html">画CNN结构的网站NN-SVG</a>：</p><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/image-20221002191424992.png" style="zoom: 50%;"></p><p>来定义一下模型结构呐，很简单只有3个卷积层：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># models.py文件</span><br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SRCNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, inputChannel=<span class="hljs-number">1</span>, outputChannel=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>(SRCNN, self).__init__()<br>        self.conv1 = nn.Conv2d(inputChannel, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">9</span>,  stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">9</span>//<span class="hljs-number">2</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>)<br>        self.conv3 = nn.Conv2d(<span class="hljs-number">32</span>, outputChannel, kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">5</span>//<span class="hljs-number">2</span>)<br>        self.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.relu(self.conv1(x))<br>        x = self.relu(self.conv2(x))<br>        x = self.conv3(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><h3 id="数据预处理">3.1 数据预处理</h3><h4 id="rgb和ycbcr的转换">3.1.1 RGB和YCbCr的转换</h4><div class="note note-info">            <p>因为涉及到了YCbCr颜色模式，所以<a href="http://t.csdn.cn/ASmUY">补充知识</a>:</p><p><strong>RGB</strong>:是依据人眼识别的颜色定义出的空间，可表示大部分颜色。但在科学研究一般不采用RGB颜色空间，因为它的细节难以进行数字化的调整。<u>它将色调，亮度，饱和度三个量放在一起表示，很难分开</u>。它是最通用的面向硬件的彩色模型。该模型用于彩色监视器和一大类彩色视频摄像。</p><p><strong>YUV:</strong>在YUV空间中，每一个颜色有<u>一个亮度信号Y，和两个色度信号U和V</u>。亮度信号是强度的感觉，它和色度信号断开，这样的话强度就可以在不影响颜色的情况下改变。YUV使用RGB的信息，但它从全彩色图像中产生一个黑白图像，然后提取出三个主要的颜色变成两个额外的信号来描述颜色。把这三个信号组合回来就可以产生一个全彩色图像。</p><p><strong>YCbCr:</strong>YUV的国际标准化变种,是YUV经过缩放和偏移的翻版。其中Y与YUV中的Y含义一致,Cb &amp; Cr同样都指色彩, 只是在表示方法上不同而已。</p><p><strong>如何转换：</strong>OpenCV提供了他们之间互相转换的函数~当然也可以自己写公式来算，代码里是自己算了嘎</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">t1 = cv2.imread(<span class="hljs-string">&#x27;data/Set5/baby.png&#x27;</span>)<br>t1 = cv2.cvtColor(t1, cv2.COLOR_RGB2YCrCb) <span class="hljs-comment"># RGB 2 YCbCr</span><br></code></pre></td></tr></table></figure>          </div><p>公式属实是不用记我觉得：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># utils.py</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_rgb_to_y</span>(<span class="hljs-params">img</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(img) == np.ndarray:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">16.</span> + (<span class="hljs-number">64.738</span> * img[:, :, <span class="hljs-number">0</span>] + <span class="hljs-number">129.057</span> * img[:, :, <span class="hljs-number">1</span>] + <span class="hljs-number">25.064</span> * img[:, :, <span class="hljs-number">2</span>]) / <span class="hljs-number">256.</span><br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span>(img) == torch.Tensor:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(img.shape) == <span class="hljs-number">4</span>:<br>            img = img.squeeze(<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">16.</span> + (<span class="hljs-number">64.738</span> * img[<span class="hljs-number">0</span>, :, :] + <span class="hljs-number">129.057</span> * img[<span class="hljs-number">1</span>, :, :] + <span class="hljs-number">25.064</span> * img[<span class="hljs-number">2</span>, :, :]) / <span class="hljs-number">256.</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&#x27;Unknown Type&#x27;</span>, <span class="hljs-built_in">type</span>(img))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_rgb_to_ycbcr</span>(<span class="hljs-params">img</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(img) == np.ndarray:<br>        y = <span class="hljs-number">16.</span> + (<span class="hljs-number">64.738</span> * img[:, :, <span class="hljs-number">0</span>] + <span class="hljs-number">129.057</span> * img[:, :, <span class="hljs-number">1</span>] + <span class="hljs-number">25.064</span> * img[:, :, <span class="hljs-number">2</span>]) / <span class="hljs-number">256.</span><br>        cb = <span class="hljs-number">128.</span> + (-<span class="hljs-number">37.945</span> * img[:, :, <span class="hljs-number">0</span>] - <span class="hljs-number">74.494</span> * img[:, :, <span class="hljs-number">1</span>] + <span class="hljs-number">112.439</span> * img[:, :, <span class="hljs-number">2</span>]) / <span class="hljs-number">256.</span><br>        cr = <span class="hljs-number">128.</span> + (<span class="hljs-number">112.439</span> * img[:, :, <span class="hljs-number">0</span>] - <span class="hljs-number">94.154</span> * img[:, :, <span class="hljs-number">1</span>] - <span class="hljs-number">18.285</span> * img[:, :, <span class="hljs-number">2</span>]) / <span class="hljs-number">256.</span><br>        <span class="hljs-keyword">return</span> np.array([y, cb, cr]).transpose([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span>(img) == torch.Tensor:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(img.shape) == <span class="hljs-number">4</span>:<br>            img = img.squeeze(<span class="hljs-number">0</span>)<br>        y = <span class="hljs-number">16.</span> + (<span class="hljs-number">64.738</span> * img[<span class="hljs-number">0</span>, :, :] + <span class="hljs-number">129.057</span> * img[<span class="hljs-number">1</span>, :, :] + <span class="hljs-number">25.064</span> * img[<span class="hljs-number">2</span>, :, :]) / <span class="hljs-number">256.</span><br>        cb = <span class="hljs-number">128.</span> + (-<span class="hljs-number">37.945</span> * img[<span class="hljs-number">0</span>, :, :] - <span class="hljs-number">74.494</span> * img[<span class="hljs-number">1</span>, :, :] + <span class="hljs-number">112.439</span> * img[<span class="hljs-number">2</span>, :, :]) / <span class="hljs-number">256.</span><br>        cr = <span class="hljs-number">128.</span> + (<span class="hljs-number">112.439</span> * img[<span class="hljs-number">0</span>, :, :] - <span class="hljs-number">94.154</span> * img[<span class="hljs-number">1</span>, :, :] - <span class="hljs-number">18.285</span> * img[<span class="hljs-number">2</span>, :, :]) / <span class="hljs-number">256.</span><br>        <span class="hljs-keyword">return</span> torch.cat([y, cb, cr], <span class="hljs-number">0</span>).permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&#x27;Unknown Type&#x27;</span>, <span class="hljs-built_in">type</span>(img))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_ycbcr_to_rgb</span>(<span class="hljs-params">img</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(img) == np.ndarray:<br>        r = <span class="hljs-number">298.082</span> * img[:, :, <span class="hljs-number">0</span>] / <span class="hljs-number">256.</span> + <span class="hljs-number">408.583</span> * img[:, :, <span class="hljs-number">2</span>] / <span class="hljs-number">256.</span> - <span class="hljs-number">222.921</span><br>        g = <span class="hljs-number">298.082</span> * img[:, :, <span class="hljs-number">0</span>] / <span class="hljs-number">256.</span> - <span class="hljs-number">100.291</span> * img[:, :, <span class="hljs-number">1</span>] / <span class="hljs-number">256.</span> - <span class="hljs-number">208.120</span> * img[:, :, <span class="hljs-number">2</span>] / <span class="hljs-number">256.</span> + <span class="hljs-number">135.576</span><br>        b = <span class="hljs-number">298.082</span> * img[:, :, <span class="hljs-number">0</span>] / <span class="hljs-number">256.</span> + <span class="hljs-number">516.412</span> * img[:, :, <span class="hljs-number">1</span>] / <span class="hljs-number">256.</span> - <span class="hljs-number">276.836</span><br>        <span class="hljs-keyword">return</span> np.array([r, g, b]).transpose([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">type</span>(img) == torch.Tensor:<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(img.shape) == <span class="hljs-number">4</span>:<br>            img = img.squeeze(<span class="hljs-number">0</span>)<br>        r = <span class="hljs-number">298.082</span> * img[<span class="hljs-number">0</span>, :, :] / <span class="hljs-number">256.</span> + <span class="hljs-number">408.583</span> * img[<span class="hljs-number">2</span>, :, :] / <span class="hljs-number">256.</span> - <span class="hljs-number">222.921</span><br>        g = <span class="hljs-number">298.082</span> * img[<span class="hljs-number">0</span>, :, :] / <span class="hljs-number">256.</span> - <span class="hljs-number">100.291</span> * img[<span class="hljs-number">1</span>, :, :] / <span class="hljs-number">256.</span> - <span class="hljs-number">208.120</span> * img[<span class="hljs-number">2</span>, :, :] / <span class="hljs-number">256.</span> + <span class="hljs-number">135.576</span><br>        b = <span class="hljs-number">298.082</span> * img[<span class="hljs-number">0</span>, :, :] / <span class="hljs-number">256.</span> + <span class="hljs-number">516.412</span> * img[<span class="hljs-number">1</span>, :, :] / <span class="hljs-number">256.</span> - <span class="hljs-number">276.836</span><br>        <span class="hljs-keyword">return</span> torch.cat([r, g, b], <span class="hljs-number">0</span>).permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">&#x27;Unknown Type&#x27;</span>, <span class="hljs-built_in">type</span>(img))<br></code></pre></td></tr></table></figure><p>试一下效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br><br>    img = cv2.imread(<span class="hljs-string">&#x27;data/Set5/original/baby.png&#x27;</span>)  <span class="hljs-comment"># cv2读进来是BGR格式，需要转成RGB</span><br>    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  <span class="hljs-comment"># BGR 2 RGB</span><br><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>    plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    plt.imshow(img)<br><br>    img = convert_rgb_to_ycbcr(img)  <span class="hljs-comment"># RGB 2 YCbCr</span><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>    plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;YCbCr&#x27;</span>)<br>    plt.imshow(img / <span class="hljs-number">255</span>)<br><br>    img = convert_ycbcr_to_rgb(img)  <span class="hljs-comment"># YCbCr 2 RGB</span><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>    plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;Cycle&#x27;</span>)<br>    plt.imshow((img // <span class="hljs-number">1</span>).astype(np.uint8))<br><br>    img = convert_rgb_to_y(img)  <span class="hljs-comment"># 只保留Y通道</span><br>    plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>)<br>    plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;Y&#x27;</span>)<br>    plt.imshow((img // <span class="hljs-number">1</span>).astype(np.uint8))<br><br>    plt.show()<br></code></pre></td></tr></table></figure><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/image-20221002212616865.png"></p><h4 id="把原数据集切成小块patch进行处理">3.1.2把原数据集切成小块(Patch)进行处理</h4><p>代码里用到了<a href="http://t.csdn.cn/XNKx0">h5文件</a>，浅浅学习一下。</p><p>HDF(Hierarchical DataFormat，层次数据格式)是一种设计用于存储和组织大量数据的文件格式，最开始由美国国家超算中心研发，后来由一个非盈利组织HDFGroup支持。h5是HDF5文件格式的后缀。h5文件对于存储大量数据而言拥有极大的优势。</p><p>h5文件中有两个核心的概念：组<code>group</code>和数据集<code>dataset</code>,一个h5文件有类似文件系统的组织结构：dataset是文件，group是文件夹，它下面可以包含多个文件夹(group)和多个文件(dataset)。</p><ul><li><strong>dataset：</strong>类似数组组织形式的数据集合，像numpy数组一样工作，一个dataset即一个numpy.ndarray</li><li><strong>group：</strong>包含了其它dataset(数组)和其它group，像字典一样工作。</li></ul><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2J1Y2hpZGFuaHVhbmc=,size_16,color_FFFFFF,t_70.png" style="zoom: 67%;"></p><p>读h5文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Reading h5 file </span><br><br><span class="hljs-keyword">import</span> h5py<br><span class="hljs-keyword">with</span> h5py.File(<span class="hljs-string">&#x27;cat_dog.h5&#x27;</span>,<span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> f.keys():<br>        <span class="hljs-built_in">print</span>(f[key], key, f[key].name) <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">结果：</span><br><span class="hljs-string">&lt;HDF5 group &quot;/dogs&quot; (1 members)&gt; dogs /dogs</span><br><span class="hljs-string">&lt;HDF5 dataset &quot;list_classes&quot;: shape (2,), type &quot;|S7&quot;&gt; list_classes /list_classes</span><br><span class="hljs-string">&lt;HDF5 dataset &quot;train_set_x&quot;: shape (209, 64, 64, 3), type &quot;|u1&quot;&gt; train_set_x /train_set_x</span><br><span class="hljs-string">&lt;HDF5 dataset &quot;train_set_y&quot;: shape (209,), type &quot;&lt;i8&quot;&gt; train_set_y /train_set_y</span><br><span class="hljs-string"></span><br><span class="hljs-string">代码解析：</span><br><span class="hljs-string">文件对象f它表示h5文件的根目录(root group),前面说了group是按字典的方式工作的,通过f.keys()来找到根目录下的所有dataset和group的key，然后通过key来访问各个dataset或group对象。</span><br><span class="hljs-string"></span><br><span class="hljs-string">结果解析：</span><br><span class="hljs-string">1.我们可以发现这个h5文件下有1个叫dogs的文件夹(group)和3个文件(dataset)它们分别叫list_classes,train_set_x,train_set_y它们的shape都可知。dogs group下有一个成员但我们不知道它是group还是dataset。</span><br><span class="hljs-string">2.我们可以发现key和name的区别:   </span><br><span class="hljs-string">上层group对象是通过key来访问下层dataset或group的而不是通过name来访问的；    </span><br><span class="hljs-string">因为name属性它是dataset或group的绝对路径并非是真正的&quot;name&quot;，key才是真正的&quot;name&quot;。     </span><br><span class="hljs-string">name绝对路径：比如下文中访问name得到：/dogs/husky，它表示根目录下有dogs这个挂载点，dogs下又挂载了husky。</span><br><span class="hljs-string">&quot;&quot;&quot;</span>  <br>    dogs_group =  f[<span class="hljs-string">&quot;dogs&quot;</span>]<br>    <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> dogs_group.keys():<br>        <span class="hljs-built_in">print</span>(dogs_group[key], dogs_group[key].name)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">结果：</span><br><span class="hljs-string">&lt;HDF5 dataset &quot;husky&quot;: shape (64, 64, 3), type &quot;&lt;f8&quot;&gt; /dogs/husky</span><br><span class="hljs-string">可见dogs文件夹下有个key为husky的文件dataset，可以通过 dogs_group[key].value访问它的值</span><br><span class="hljs-string">&quot;&quot;&quot;</span>   <br><br></code></pre></td></tr></table></figure><p>写h5文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Writing h5</span><br><br><span class="hljs-keyword">import</span> h5py<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">with</span> h5py.File(<span class="hljs-string">&quot;animals.h5&quot;</span>, <span class="hljs-string">&#x27;a&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-comment"># 根目录下创建一个总览介绍动物种类的dataset,字符串应当字节化，故使用.encode()方法</span><br>    f.create_dataset(<span class="hljs-string">&#x27;animals_included&#x27;</span>, data=np.array([<span class="hljs-string">&quot;dogs&quot;</span>.encode(),<span class="hljs-string">&quot;cats&quot;</span>.encode()])) <br>    <br>    <span class="hljs-comment"># 在根目录下创建gruop文件夹:dogs</span><br>    dogs_group = f.create_group(<span class="hljs-string">&quot;dogs&quot;</span>) <br>    <br>    <span class="hljs-comment"># 根目录下创建一个含5张猫图片的dataset文件</span><br>    f.create_dataset(<span class="hljs-string">&#x27;cats&#x27;</span> ,data = np.array(np.random.randn(<span class="hljs-number">5</span>,<span class="hljs-number">64</span>,<span class="hljs-number">64</span>,<span class="hljs-number">3</span>))) <br>    <br>    <span class="hljs-comment"># 在dogs文件夹下分别创建两个dataset,一张哈士奇图片和一张柴犬的图片</span><br>    dogs_group.create_dataset(<span class="hljs-string">&quot;husky&quot;</span>,data=np.random.randn(<span class="hljs-number">64</span>,<span class="hljs-number">64</span>,<span class="hljs-number">3</span>)) <br>    dogs_group.create_dataset(<span class="hljs-string">&quot;shiba&quot;</span>,data=np.random.randn(<span class="hljs-number">64</span>,<span class="hljs-number">64</span>,<span class="hljs-number">3</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 检查一下上面创建的文件</span><br><br><span class="hljs-keyword">with</span> h5py.File(<span class="hljs-string">&#x27;animals.h5&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    <span class="hljs-keyword">for</span> fkey <span class="hljs-keyword">in</span> f.keys():<br>        <span class="hljs-built_in">print</span>(f[fkey], fkey)<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    结果：</span><br><span class="hljs-string">    &lt;HDF5 dataset &quot;animals_included&quot;: shape (2,), type &quot;|S4&quot;&gt; animals_included</span><br><span class="hljs-string">&lt;HDF5 dataset &quot;cats&quot;: shape (5, 64, 64, 3), type &quot;&lt;f8&quot;&gt; cats</span><br><span class="hljs-string">&lt;HDF5 group &quot;/dogs&quot; (2 members)&gt; dogs</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br>    <br>    dogs_group = f[<span class="hljs-string">&quot;dogs&quot;</span>] <span class="hljs-comment"># 从上面的结果可以发现根目录/下有个dogs的group,所以我们来研究一下它</span><br>    <span class="hljs-keyword">for</span> dkey <span class="hljs-keyword">in</span> dogs_group.keys():<br>        <span class="hljs-built_in">print</span>(dkey, dogs_group[dkey], dogs_group[dkey].name, dogs_group[dkey].value)<br>        <br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">  husky &lt;HDF5 dataset &quot;husky&quot;: shape (64, 64, 3), type &quot;&lt;f8&quot;&gt; /dogs/husky [[[ 6.22221467e-01  2.29412386e-01  1.70099600e-01]</span><br><span class="hljs-string">  [-9.53310941e-01 -1.65325168e+00  6.50092663e-02]</span><br><span class="hljs-string">  [-2.33444396e-01  5.32328485e-01 -1.23046495e+00]</span><br><span class="hljs-string">  ...</span><br><span class="hljs-string">  [-8.27186186e-04 -9.54570238e-01  1.20224835e+00]</span><br><span class="hljs-string">  [-3.03556381e-01  5.30470941e-01 -1.49928878e-01]</span><br><span class="hljs-string">  [ 5.24641964e-01 -1.55304472e+00  1.30016600e+00]]</span><br><span class="hljs-string">  ...</span><br><span class="hljs-string">  &#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>好嘞试验完成，开始正式干活儿，首先把训练集文件夹里的图片数据切成小块，这里用了T91数据集的图片，函数如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># prepare.py</span><br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> h5py<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> PIL.Image <span class="hljs-keyword">as</span> Image<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> convert_rgb_to_y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">args</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    为训练过程制作.h5文件格式的数据集，把训练集文件夹里的图片数据切成小块</span><br><span class="hljs-string">    :param args: 相关设置参数</span><br><span class="hljs-string">    :return: 保存h5数据集文件到output_path</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    h5_file = h5py.File(args.output_path, <span class="hljs-string">&#x27;w&#x27;</span>)<br><br>    lr_patches = []<br>    hr_patches = []<br><br>    <span class="hljs-keyword">for</span> image_path <span class="hljs-keyword">in</span> os.listdir(args.images_dir):<br>        <span class="hljs-comment"># 打开图片并转为RGB形式</span><br>        hr = Image.<span class="hljs-built_in">open</span>(os.path.join(args.images_dir, image_path)).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br><br>        <span class="hljs-comment"># 缩放hr图片，使hr_width和hr_weight能被缩放倍数scale整除</span><br>        hr_width = (hr.width // args.scale) * args.scale<br>        hr_height = (hr.height // args.scale) * args.scale<br>        hr = hr.resize((hr_width, hr_height), resample=Image.BICUBIC)<br><br>        <span class="hljs-comment"># 降采样为lr图片， 再上采样为同样大小</span><br>        lr = hr.resize((hr_width // args.scale, hr_height // args.scale), resample=Image.BICUBIC)<br>        lr = lr.resize((lr.width * args.scale, lr.height * args.scale), resample=Image.BICUBIC)<br><br>        <span class="hljs-comment"># 转换为numpy数组，继而转换为单通道Y图片</span><br>        hr = np.array(hr).astype(np.float32)<br>        lr = np.array(lr).astype(np.float32)<br>        hr = convert_rgb_to_y(hr)<br>        lr = convert_rgb_to_y(lr)<br><br>        <span class="hljs-comment"># shape: H W C</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, lr.shape[<span class="hljs-number">0</span>] - args.patch_size + <span class="hljs-number">1</span>, args.stride):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, lr.shape[<span class="hljs-number">1</span>] - args.patch_size + <span class="hljs-number">1</span>, args.stride):<br>                lr_patches.append(lr[i:i + args.patch_size, j:j + args.patch_size])<br>                hr_patches.append(hr[i:i + args.patch_size, j:j + args.patch_size])<br><br>    <span class="hljs-comment"># ndarray(21910, 33, 33), 21910张patch</span><br>    lr_patches = np.array(lr_patches)<br>    hr_patches = np.array(hr_patches)<br><br>    h5_file.create_dataset(<span class="hljs-string">&#x27;lr&#x27;</span>, data=lr_patches)<br>    h5_file.create_dataset(<span class="hljs-string">&#x27;hr&#x27;</span>, data=hr_patches)<br><br>    h5_file.close()<br>    <br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    文件内容如下：</span><br><span class="hljs-string">     —————————————————————————————————————————</span><br><span class="hljs-string">| dataset：&#x27;lr&#x27;, ndarray(21910, 33, 33)  |</span><br><span class="hljs-string">——————————————————————————————————————————</span><br><span class="hljs-string">| dataset：&#x27;hr&#x27;, ndarray(21910, 33, 33)  |</span><br><span class="hljs-string">——————————————————————————————————————————</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>    <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--images-dir&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;data/T91&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--output-path&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;data/train/train.h5&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--patch-size&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">33</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--stride&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">14</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--scale&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">2</span>)<br>    args = parser.parse_args()<br>    train(args)<br></code></pre></td></tr></table></figure><p>类似地，制作测试集，主体过程与上相同：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># prepare.py</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">eval</span>(<span class="hljs-params">args</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        为测试过程制作.h5文件格式的数据集，把测试集文件夹里的图片数据切成小块</span><br><span class="hljs-string">        :param args: 相关设置参数</span><br><span class="hljs-string">        :return: 保存h5数据集文件到output_path</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    h5_file = h5py.File(args.output_path, <span class="hljs-string">&#x27;w&#x27;</span>)<br><br>    lr_group = h5_file.create_group(<span class="hljs-string">&#x27;lr&#x27;</span>)<br>    hr_group = h5_file.create_group(<span class="hljs-string">&#x27;hr&#x27;</span>)<br><br>    <span class="hljs-keyword">for</span> i, image_path <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(os.listdir(args.images_dir)):<br>        hr = Image.<span class="hljs-built_in">open</span>(os.path.join(args.images_dir, image_path)).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>        hr_width = (hr.width // args.scale) * args.scale<br>        hr_height = (hr.height // args.scale) * args.scale<br>        hr = hr.resize((hr_width, hr_height), resample=Image.BICUBIC)<br>        lr = hr.resize((hr_width // args.scale, hr_height // args.scale), resample=Image.BICUBIC)<br>        lr = lr.resize((lr.width * args.scale, lr.height * args.scale), resample=Image.BICUBIC)<br>        hr = np.array(hr).astype(np.float32)<br>        lr = np.array(lr).astype(np.float32)<br>        hr = convert_rgb_to_y(hr)<br>        lr = convert_rgb_to_y(lr)<br><br>        lr_group.create_dataset(<span class="hljs-built_in">str</span>(i), data=lr)<br>        hr_group.create_dataset(<span class="hljs-built_in">str</span>(i), data=hr)<br><br>    h5_file.close()<br>    <br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    文件内容如下：两个group里分别保存了编号不同的图片</span><br><span class="hljs-string">     —————————————————————————————————————————</span><br><span class="hljs-string">| group：&#x27;lr&#x27;                            |</span><br><span class="hljs-string">|  [dataset: 0, ndarray(512, 512)]       |</span><br><span class="hljs-string">|  [dataset: 1, ndarray(288, 288)]       |</span><br><span class="hljs-string">|  ...                                   |</span><br><span class="hljs-string">——————————————————————————————————————————</span><br><span class="hljs-string">| group：&#x27;hr&#x27;                            |</span><br><span class="hljs-string">|  [dataset: 0, ndarray(512, 512)]       |</span><br><span class="hljs-string">|  [dataset: 1, ndarray(288, 288)]       |</span><br><span class="hljs-string">|  ...                                   |</span><br><span class="hljs-string">——————————————————————————————————————————</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure><h4 id="实现dataset">3.1.3 实现Dataset</h4><p>因为Pytorch读取数据需要通过Dataset和Dataloader实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> h5py<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TrainDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, h5_file_name</span>):<br>        <span class="hljs-built_in">super</span>(TrainDataset, self).__init__()<br>        self.h5_file_name = h5_file_name<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-keyword">with</span> h5py.File(self.h5_file_name, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-comment"># 扩充一维作为通道数，/255使图片像素取值规范到[0, 1]</span><br>            lr = np.expand_dims(f[<span class="hljs-string">&#x27;lr&#x27;</span>][item] / <span class="hljs-number">255.</span>, <span class="hljs-number">0</span>)<br>            hr = np.expand_dims(f[<span class="hljs-string">&#x27;hr&#x27;</span>][item] / <span class="hljs-number">255.</span>, <span class="hljs-number">0</span>)<br>            <span class="hljs-keyword">return</span> lr, hr<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">with</span> h5py.File(self.h5_file_name, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(f[<span class="hljs-string">&#x27;lr&#x27;</span>])<br></code></pre></td></tr></table></figure><p>效果测试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    dataset = TrainDataset(<span class="hljs-string">&#x27;./data/train/train.h5&#x27;</span>)<br>    plt.subplot(<span class="hljs-number">121</span>)<br>    plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;lr&#x27;</span>)<br>    plt.imshow(dataset[<span class="hljs-number">2</span>][<span class="hljs-number">0</span>].squeeze())<br>    plt.subplot(<span class="hljs-number">122</span>)<br>    plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;hr&#x27;</span>)<br>    plt.imshow(dataset[<span class="hljs-number">2</span>][<span class="hljs-number">1</span>].squeeze())<br>    plt.show()<br></code></pre></td></tr></table></figure><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/image-20221003171202280.png" style="zoom: 50%;"></p><p>同样实现测试数据集的Dataset：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># datasets.py</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">EvalDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, h5_file_name</span>):<br>        <span class="hljs-built_in">super</span>(EvalDataset, self).__init__()<br>        self.h5_file_name = h5_file_name<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, item</span>):<br>        <span class="hljs-keyword">with</span> h5py.File(self.h5_file_name, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-comment"># h5文件的索引只能是字符串</span><br>            lr = f[<span class="hljs-string">&#x27;lr&#x27;</span>][<span class="hljs-built_in">str</span>(item)]<br>            lr = np.expand_dims(f[<span class="hljs-string">&#x27;lr&#x27;</span>][<span class="hljs-built_in">str</span>(item)][:, :] / <span class="hljs-number">255.</span>, <span class="hljs-number">0</span>)<br>            hr = np.expand_dims(f[<span class="hljs-string">&#x27;hr&#x27;</span>][<span class="hljs-built_in">str</span>(item)][:, :] / <span class="hljs-number">255.</span>, <span class="hljs-number">0</span>)<br>            <span class="hljs-keyword">return</span> lr, hr<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">with</span> h5py.File(self.h5_file, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(f[<span class="hljs-string">&#x27;lr&#x27;</span>])<br></code></pre></td></tr></table></figure><h3 id="训练过程">3.2 训练过程</h3><p>工具函数和工具类。AverageMeter用于累加记录训练过程中的loss和psnr。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># utils.py</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calc_psnr</span>(<span class="hljs-params">img1, img2</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">10.</span> * torch.log10(<span class="hljs-number">1.</span> / torch.mean((img1 - img2) ** <span class="hljs-number">2</span>))<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AverageMeter</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.reset()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reset</span>(<span class="hljs-params">self</span>):<br>        self.val = <span class="hljs-number">0</span><br>        self.avg = <span class="hljs-number">0</span><br>        self.<span class="hljs-built_in">sum</span> = <span class="hljs-number">0</span><br>        self.count = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, val, n=<span class="hljs-number">1</span></span>):<br>        self.val = val<br>        self.<span class="hljs-built_in">sum</span> += val * n<br>        self.count += n<br>        self.avg = self.<span class="hljs-built_in">sum</span> / self.count<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># train.py</span><br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> copy<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">import</span> torch.backends.cudnn <span class="hljs-keyword">as</span> cudnn<br><span class="hljs-keyword">from</span> torch.utils.data.dataloader <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">from</span> models <span class="hljs-keyword">import</span> SRCNN<br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> TrainDataset, EvalDataset<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> AverageMeter, calc_psnr<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">args</span>):<br>    device = torch.device(<span class="hljs-string">&#x27;cuda:0&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>)<br><br>    model = SRCNN().to(device)<br>    criterion = nn.MSELoss()<br>    optimizer = optim.Adam([<br>        &#123;<span class="hljs-string">&#x27;params&#x27;</span>: model.conv1.parameters()&#125;,<br>        &#123;<span class="hljs-string">&#x27;params&#x27;</span>: model.conv2.parameters()&#125;,<br>        &#123;<span class="hljs-string">&#x27;params&#x27;</span>: model.conv3.parameters(), <span class="hljs-string">&#x27;lr&#x27;</span>: args.lr * <span class="hljs-number">0.1</span>&#125;  <span class="hljs-comment"># 对最后一层卷积层的参数衰减学习率</span><br>    ], lr=args.lr)<br><br>    train_dataset = TrainDataset(args.train_file)<br>    train_dataloader = DataLoader(dataset=train_dataset,<br>                                  batch_size=args.batch_size,<br>                                  shuffle=<span class="hljs-literal">True</span>,<br>                                  num_workers=args.num_workers,  <span class="hljs-comment"># 工作进程，像是虚拟存储器中的页表机制</span><br>                                  pin_memory=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># 锁页内存，不换出内存</span><br>                                  drop_last=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 不取余，丢弃不足batchSize的图像</span><br><br>    best_weights = copy.deepcopy(model.state_dict())<br>    best_epoch = <span class="hljs-number">0</span><br>    best_psnr = <span class="hljs-number">0.0</span><br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(args.num_epochs):<br>        model.train()<br>        epoch_losses = AverageMeter()<br><br>        <span class="hljs-keyword">for</span> batch, (inputs, labels) <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">enumerate</span>(train_dataloader), total=<span class="hljs-built_in">len</span>(train_dataset)//args.batch_size):<br><br>            inputs = inputs.to(device)<br>            labels = labels.to(device)<br><br>            preds = model(inputs)<br><br>            loss = criterion(preds, labels)  <span class="hljs-comment"># 和普通卷积神经网络一样计算loss &amp; backward</span><br>            epoch_losses.update(loss.item(), <span class="hljs-built_in">len</span>(inputs))<br><br>            optimizer.zero_grad()<br>            loss.backward()<br>            optimizer.step()<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch:&#123;&#125;  train-loss:&#123;:.6f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, epoch_losses.avg))<br>        <span class="hljs-keyword">if</span> epoch % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:<br>            torch.save(model.state_dict(), os.path.join(args.outputs_dir, <span class="hljs-string">&#x27;epoch_&#123;&#125;.pth&#x27;</span>.<span class="hljs-built_in">format</span>(epoch)))<br><br>        <span class="hljs-comment"># 测试过程</span><br>        model.<span class="hljs-built_in">eval</span>()<br>        epoch_psnr = AverageMeter()<br>        eval_dataset = EvalDataset(args.eval_file)<br>        eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=<span class="hljs-number">1</span>)<br><br>        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> eval_dataloader:<br>            <span class="hljs-comment"># 网络传播得到pred</span><br>            inputs, labels = data<br>            inputs = inputs.to(device)<br>            labels = labels.to(device)<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                preds = model(inputs).clamp(<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>)<br><br>            <span class="hljs-comment"># 进而计算预测值和真实HR的PSNR</span><br>            epoch_psnr.update(calc_psnr(preds, labels), <span class="hljs-built_in">len</span>(inputs))<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;eval psnr: &#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch_psnr.avg))<br><br>        <span class="hljs-keyword">if</span> epoch_psnr.avg &gt; best_psnr:<br>            best_epoch = epoch<br>            best_psnr = epoch_psnr.avg<br>            best_weights = copy.deepcopy(model.state_dict())<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;best epoch: &#123;&#125;, psnr: &#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(best_epoch, best_psnr))<br>            torch.save(best_weights, os.path.join(args.outputs_dir, <span class="hljs-string">&#x27;best.pth&#x27;</span>))<br></code></pre></td></tr></table></figure><p>设置随机数种子和参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># train.py</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">setup_seed</span>(<span class="hljs-params">seed</span>):<br>    torch.manual_seed(seed)<br>    torch.cuda.manual_seed_all(seed)<br>    cudnn.benchmark = <span class="hljs-literal">True</span><br>    cudnn.deterministic = <span class="hljs-literal">True</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 加载设置</span><br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--train-file&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;./data/train/train.h5&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--eval-file&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;./data/test/test.h5&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--outputs-dir&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;save&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--scale&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">3</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--lr&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">1e-4</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--batch-size&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">16</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--num-epochs&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">400</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--num-workers&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">3</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--seed&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">123</span>)<br>    args = parser.parse_args()<br><br>    <span class="hljs-comment"># 设置文件保存位置</span><br>    args.outputs_dir = os.path.join(args.outputs_dir, <span class="hljs-string">&#x27;x&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(args.scale))<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(args.outputs_dir):<br>        os.makedirs(args.outputs_dir)<br><br>    <span class="hljs-comment"># 设置随机数种子</span><br>    setup_seed(args.seed)<br>    train(args)<br></code></pre></td></tr></table></figure><p>训练到250个epoch停啦：</p><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/image-20221003211908254.png" style="zoom: 67%;"></p><p>毕竟还是有些古早的技术了，恢复质量感觉不很理想，也有可能是我没有训练够轮数，从左到右：LR、SRCNN、BICUBIC</p><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/image-20221003211740408.png"></p><p>github仓库的PSNR:</p><p><img src="/2022/10/01/%E3%80%90%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E3%80%91SRCNN/image-20221003213024246.png" style="zoom: 50%;"></p><p>明天就要开组会了，还没做PPT，实验也还没跑完，说实话有点子绝望:(</p>]]></content>
    
    
    
    <tags>
      
      <tag>论文</tag>
      
      <tag>超分辨率</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【气象降尺度】2017-DeepSD:通过SR生成高分辨率气候变化预测-Thomas-KDD</title>
    <link href="/2022/10/01/%E3%80%90%E6%B0%94%E8%B1%A1%E9%99%8D%E5%B0%BA%E5%BA%A6%E3%80%912017-DeepSD-Thomas/"/>
    <url>/2022/10/01/%E3%80%90%E6%B0%94%E8%B1%A1%E9%99%8D%E5%B0%BA%E5%BA%A6%E3%80%912017-DeepSD-Thomas/</url>
    
    <content type="html"><![CDATA[<h2 id="摘要">摘要</h2><p>地球系统模型ESM(Earth SystemModels)在空间分辨率上过于粗糙，本文提出了一个通用的堆叠SRCNN网络DeepSD用于气候变量的统计降尺度。</p><p>DeepSD对SRCNN进行了补充，使用了多尺度的输入通道(?)。</p><p>与偏差校正空间分解等四种统计降尺度方法进行比较，将美国大陆的日降水量从1°(100km)降至1/8°(12.5km)。</p><p>文章中还讨论了一个使用NASA EarthExchange(NEX)的框架，对具有多种排放场景的20多个ESM进行降尺度。</p><h2 id="引言">1 引言</h2><p>气候对农业、交通、能源、人类安全等都有很大影响。地球系统模型(ESMs)是在大型超级计算机上运行的基于物理的数值模型，用于预测地球对大气温室气体排放情景变化的响应。</p><p>ESM的输出是许多学科用于研究气候变化的主要数据产品，提供了温度、降水、风、湿度、压力等大量气候变量。</p><p>但是ESM在计算上的要求使得其空间分辨率限制在1°到3°以内，这样的分辨率太过粗糙，无法解决关键的物理过程，也无法评估这些气候变量造成的局部本地影响。</p><p>传统降尺度方法：</p><ul><li>动态降尺度(区域气候模型RCM)划分更小的网格</li><li>统计降尺度(StatisticalDownscaling,SD)通过统计学习/机器学习方法，学习了一种函数形式，通过合并观测数据，把ESM从低分辨率映射到高分辨率</li></ul><p>目前还不知道有任何SD方法能够明确地捕获低分辨率和高分辨率气候数据中的空间依赖性。且传统方法需要高分辨率的观测数据，这是观测数据很少的贫穷地区难以获取的。而超分辨率问题(SR)和统计降尺度问题(SD)具有很大的相似性。</p><p>最后，结合本文的超分辨率方法、利用NASA的地球交换(NEX)平台，本文提出了一个框架，对美国大陆（CONUS）的四种排放情景，在每日时间尺度上进行低尺度的地球系统模型（ESMs）集成。</p><blockquote><p>NEX-DCP30数据集由美国本土的downscale气候情景组成，这些情景源自在CMIP5下进行的大气环流模式(GCM)和IPCC第五次评估报告制定的四种温室气体排放情景，称为代表性浓度路径(RCP)。这些数据集的目的是提供一组高分辨率、偏差校正的气候变化预测，可用于评估气候变化对更细尺度气候梯度敏感过程的影响以及局部地形对气候条件的影响。该数据集包含涵盖1950 年至 2005 年（回顾性运行）和 2006 年至 2099年（预期运行）期间的月度预测。</p></blockquote><p>DeepSD：SOTA、可迁移、提供生成高分辨率的降尺度产品的新思路。</p><h2 id="地球科学数据">2 地球科学数据</h2><p>地球科学数据来自各种领域，比如气候模拟、遥感数据和气象站观测。</p><p>这类数据的时空性质给计算和存储带来了巨大的挑战(需要的存储量大)，并且分析这些复杂的数据集需要专业的技术和知识.</p><h2 id="英语">英语</h2><table><thead><tr class="header"><th>单词</th><th>中文</th></tr></thead><tbody><tr class="odd"><td>coarse</td><td>粗糙的</td></tr><tr class="even"><td>archive</td><td>档案</td></tr><tr class="odd"><td>archived</td><td>已归档的、存档的</td></tr><tr class="even"><td>principal</td><td>最重要的、首要的</td></tr><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td></td></tr><tr class="odd"><td></td><td></td></tr><tr class="even"><td></td><td></td></tr><tr class="odd"><td></td><td></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>论文</tag>
      
      <tag>气象降尺度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【气象降尺度】2019-基于深度学习图像超分辨率的气象数据空间降尺度-茅志仁-武汉大学</title>
    <link href="/2022/10/01/%E3%80%90%E6%B0%94%E8%B1%A1%E9%99%8D%E5%B0%BA%E5%BA%A6%E3%80%912019-%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9B%BE%E5%83%8F%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%A9%BA%E9%97%B4%E9%99%8D%E5%B0%BA%E5%BA%A6-%E8%8C%85%E5%BF%97%E4%BB%81-%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6/"/>
    <url>/2022/10/01/%E3%80%90%E6%B0%94%E8%B1%A1%E9%99%8D%E5%B0%BA%E5%BA%A6%E3%80%912019-%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9B%BE%E5%83%8F%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E6%B0%94%E8%B1%A1%E6%95%B0%E6%8D%AE%E7%A9%BA%E9%97%B4%E9%99%8D%E5%B0%BA%E5%BA%A6-%E8%8C%85%E5%BF%97%E4%BB%81-%E6%AD%A6%E6%B1%89%E5%A4%A7%E5%AD%A6/</url>
    
    <content type="html"><![CDATA[<h2 id="摘要">0 摘要</h2><p>降水数据反映到图像领域即为降水分布图；图像领域与数值降尺度类似的一个分支为图像超分辨率(SR).</p><p>DeepSD：收敛慢(不同类别气象数据训练时间成本高)、网络结构浅、插值预处理引入人为误差&amp;增加计算复杂度.</p><p>本文：提出VDSD(20层+) &amp; ResSD(60层+) &amp;ResSD+(100层+)；利用了残差学习，网络收敛有提升；去除插值预处理，通过<strong>反卷积上采样</strong>实现超分辨率重建，减小计算复杂度；将超分辨率网络模块化。</p><p>通过和气象局公共气象服务中心合作，本文以深度学习SR方法为基础，将其迁移到气象数据空间降尺度的研究上。</p><h2 id="引言">1 引言</h2><p><strong>动力降尺度：</strong>区域气候模型，利用全球气候模型提供的初始条件和边界，推测出高分辨率的气候变化。</p><p><strong>统计降尺度：</strong>对大尺度变量（如大气表面压力）和局部变量（如特定地点的风速）之间的观测建立统计关系，并检验这种关系的合理性，然后把这种关系应用于全球气候模型（GCMs）的数据，从全球气候模型（GCMs）的输出获取局部变量。</p><p>古早技术：2007年，“偏差校正空间分解”（BCSD）</p><p>DeepSD：将静态高分辨率的地形数据和低分辨率的气象数据结合起来，以缓解不适定问题。</p><p>介绍了SRCNN  VDSR  ESPCN LapSRN  SRGAN  ESRGAN</p><p>降水模式有NCEP[8]，RJTD，EC，GRAPES_MESO，NMC[11]，空间分辨率分别为25公里、25公里、12.5公里、10公里、5公里。</p>]]></content>
    
    
    
    <tags>
      
      <tag>论文</tag>
      
      <tag>气象降尺度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux/Windows下使用Anaconda安装Pytorch</title>
    <link href="/2022/09/29/%E4%BD%BF%E7%94%A8Anaconda%E5%AE%89%E8%A3%85Pytorch/"/>
    <url>/2022/09/29/%E4%BD%BF%E7%94%A8Anaconda%E5%AE%89%E8%A3%85Pytorch/</url>
    
    <content type="html"><![CDATA[<p>情况:已安装Anaconda.</p><h2 id="pytorch的安装">1 Pytorch的安装</h2><p>首先为加快下载速度将Anaconda源换为清华源：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/<br>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge<br>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/<br>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/<br>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/<br>conda config --<span class="hljs-built_in">set</span> show_channel_urls <span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure><p>可以使用以下命令查看Anaconda源的地址：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda config --show-sources<br></code></pre></td></tr></table></figure><p>由于不同的程序可能需要不同的环境，故首先创建一个新的虚拟环境(pytorch是这个环境的名字，可以自由设置)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n pytorch python=3.9<br></code></pre></td></tr></table></figure><p>切换到虚拟环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda activate pytorch<br></code></pre></td></tr></table></figure><p>查看CUDA版本:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">nvcc --version<br></code></pre></td></tr></table></figure><figure><img src="/2022/09/29/%E4%BD%BF%E7%94%A8Anaconda%E5%AE%89%E8%A3%85Pytorch/CUDA版本.png" alt="CUDA版本"><figcaption aria-hidden="true">CUDA版本</figcaption></figure><p>显示CUDA版本为11.2，到<a href="https://pytorch.org/get-started/previous-versions/">Pytorch官网</a>[CTRL+F]找一下对应的命令，似乎没有11.2版本，为保证兼容性，故用版本稍低的11.1：</p><figure><img src="/2022/09/29/%E4%BD%BF%E7%94%A8Anaconda%E5%AE%89%E8%A3%85Pytorch/Pytorch版本.png" alt="Pytorch版本"><figcaption aria-hidden="true">Pytorch版本</figcaption></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge<br></code></pre></td></tr></table></figure><p>主要是pytorch和cudatoolkit这两个包下载过程有些慢，稍等一会儿就安装完成啦~(●'◡'●)</p><h2 id="其他库的安装根据需要">2 其他库的安装（根据需要</h2><p>机器学习基础库：scikit-learn、pandas、seaborn</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda install scikit-learn<br>conda install pandas<br>conda  install seaborn<br></code></pre></td></tr></table></figure><p>进度条库tqdm:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda install -c conda-forge tqdm<br></code></pre></td></tr></table></figure><p>tensorboardX：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda install -c conda-forge tensorboardx <br></code></pre></td></tr></table></figure><p>查看安装库的情况：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda list<br></code></pre></td></tr></table></figure><h2 id="使用pycharm远程连接服务器">3 使用Pycharm远程连接服务器</h2><p>看这篇：http://t.csdn.cn/9Pu6J</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
